{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "connection_parameters = json.load(open('../connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build docker image and push the image to image registry\n",
    "\n",
    "- Run the below code from terminal or execute the next cell by updating the connection details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Run below commands from a terminal. Update the ORGNAME-ACCTNAME and username -->\n",
    "``` bash\n",
    "cd ..\n",
    "cd text2sql\n",
    "```\n",
    "> be sure your directory has changed to text2sql (validate via pwd)\n",
    "``` bash\n",
    "docker build --no-cache --platform linux/amd64 -t ORGNAME-ACCTNAME.registry.snowflakecomputing.com/llmdemo/public/images/audiollm:latest . \n",
    "\n",
    "docker login ORGNAME-ACCTNAME.registry.snowflakecomputing.com -u <username>\n",
    "\n",
    "docker push ORGNAME-ACCTNAME.registry.snowflakecomputing.com/llmdemo/public/images/audiollm:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Creating Text2SQL SPC Service\n",
    "\n",
    "Update the image line in [llm-text2sql.yaml](./llm-text2sql.yaml) to provide your orgname-accountname values\n",
    "\n",
    "ex. image: <i>myorg-myaccount</i>.registry.snowflakecomputing.com/pr_llmdemo/public/image_repo/whisper-audio2text:latest\n",
    "\n",
    "PS: <b>Run following commands using the SPCS Role, not accountadmin! (this should already be set in your [connection.json](../connection.json) file) </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PutResult(source='llm-text2sql.yaml', target='llm-text2sql.yaml', source_size=648, target_size=0, source_compression='NONE', target_compression='NONE', status='SKIPPED', message='')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "session.file.put(\"./llm-text2sql.yaml\", \"@specs\",auto_compress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the required stage\n",
    "stages=['LLM_WORKSPACE']\n",
    "for stg in stages:\n",
    "    session.sql(f'''\n",
    "                CREATE STAGE IF NOT EXISTS {stg} ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE')\n",
    "                DIRECTORY = (ENABLE = TRUE);\n",
    "                ''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='LLAMA_TEXT2SQL_SVC already exists, statement succeeded.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the service. EXTERNAL_ACCESS_INTEGRATIONS(ALLOW_ALL_EAI) is created in audio2text/audio2text_setup_code.ipynb\n",
    "session.sql('''\n",
    "create service if not exists llama_text2sql_svc\n",
    "in compute pool PR_GPU_7\n",
    "from @specs\n",
    "SPECIFICATION_FILE='llm-text2sql.yaml'\n",
    "EXTERNAL_ACCESS_INTEGRATIONS = (ALLOW_ALL_EAI)\n",
    "            ''').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The service must be in Ready State to proceed. Run the following command to confirm before proceeding to next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'READY',\n",
       " 'message': 'Running',\n",
       " 'containerName': 'text2sql-container',\n",
       " 'instanceId': '0',\n",
       " 'serviceName': 'LLAMA_TEXT2SQL_SVC',\n",
       " 'image': 'sfsenorthamerica-demo-psheehan.registry.snowflakecomputing.com/llmdemo/public/images/audiollm:latest',\n",
       " 'restartCount': 0,\n",
       " 'startTime': '2024-06-24T21:16:20Z'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Check the status of service\n",
    "import ast\n",
    "res=session.sql(''' \n",
    "SELECT SYSTEM$GET_SERVICE_STATUS('llama_text2sql_svc',1)\n",
    "''').collect()[0][0]\n",
    "ast.literal_eval(res)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  Be sure the service is in the Ready State before procedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Accessing Jupyter Lab Endpoints\n",
    "Wait for the status of the service to be Running before moving to next step. \n",
    "\n",
    "Run the below query to get the api endpoint for the <b> jupyter lab </b>. Get the <b>ingress_url </b>(this endpoint will launch jupyter notebook running Snowpark Containers)  from the below query output.\n",
    "\n",
    "Output will be similar to this:  Row(name='llm-audio-ep', port=8888, port_range=None, protocol='HTTP', is_public='true', ingress_url='yjb2m-sfsenorthamerica-demo-psheehan.snowflakecomputing.app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(name='llm-audio-ep', port=8888, port_range=None, protocol='HTTP', is_public='true', ingress_url='yjb2q-sfsenorthamerica-demo-psheehan.snowflakecomputing.app')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('''show endpoints in service llama_text2sql_svc;\n",
    "            ''').collect()[1]\n",
    "\n",
    "# Row(name='llm-audio-ep', port=8888, port_range=None, protocol='HTTP', is_public='true', ingress_url='yjb2m-sfsenorthamerica-demo-psheehan.snowflakecomputing.app')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Perform the following action on the Jupyter lab which is accessible from the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1. Open the terminal in the JupyterLab(which is running in Snowpark Containers) and run the below shell script  </b>\n",
    "\n",
    "- sh download_model.sh\n",
    "\n",
    "This file will download the Numberstation model from hugging face and downloads to the stage which is mounted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2. Run the FineTuneModel.ipynb</b>\n",
    "\n",
    "* Execute each cell by cell where we are fine tuning the model as well with our own dataset.\n",
    "\n",
    "* After executing the last cell you will be running a fast api service which will expose the Number station LLM as a api endpoint.\n",
    "\n",
    "><b> NOTE </b> : Steps 1 and 2 are one-time only; if you restart the Snowpark service, relaunch the jupyter lab from Step 4 above and then run the following terminal command:\n",
    "\n",
    "sh RunFastAPI.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Execute the below commands to create the service function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msession\u001b[49m\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mCREATE OR REPLACE FUNCTION text2sql(text TEXT)\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mRETURNS VARIANT\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mSERVICE=llama_text2sql_svc\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mENDPOINT=api\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124mAS \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/text2sql\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'''\u001b[39m)\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'session' is not defined"
     ]
    }
   ],
   "source": [
    "session.sql('''CREATE OR REPLACE FUNCTION text2sql(text TEXT)\n",
    "RETURNS VARIANT\n",
    "SERVICE=llama_text2sql_svc\n",
    "ENDPOINT=api\n",
    "AS '/text2sql' ''').collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "  File \"/var/folders/mp/y8k0fjl12sz3gbrk_v6g5nsm0000gn/T/ipykernel_28854/1169266907.py\", line 2, in <module>\n",
      "    session.sql('''\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/snowpark/_internal/telemetry.py\", line 145, in wrap\n",
      "    result = func(*args, **kwargs)\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/snowpark/dataframe.py\", line 597, in collect\n",
      "    return self._internal_collect_with_tag_no_telemetry(\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/snowpark/dataframe.py\", line 645, in _internal_collect_with_tag_no_telemetry\n",
      "    return self._session._conn.execute(\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py\", line 510, in execute\n",
      "    result_set, result_meta = self.get_result_set(\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py\", line 191, in wrap\n",
      "    raise ne.with_traceback(tb) from None\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py\", line 122, in wrap\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py\", line 612, in get_result_set\n",
      "    result = self.run_query(\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py\", line 123, in wrap\n",
      "    raise ex\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py\", line 117, in wrap\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py\", line 417, in run_query\n",
      "    raise ex\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py\", line 402, in run_query\n",
      "    results_cursor = self.execute_and_notify_query_listener(\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/snowpark/_internal/server_connection.py\", line 354, in execute_and_notify_query_listener\n",
      "    results_cursor = self._cursor.execute(query, **kwargs)\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/connector/cursor.py\", line 1080, in execute\n",
      "    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/connector/errors.py\", line 290, in errorhandler_wrapper\n",
      "    handed_over = Error.hand_to_other_handler(\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/connector/errors.py\", line 345, in hand_to_other_handler\n",
      "    cursor.errorhandler(connection, cursor, error_class, error_value)\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/snowflake/connector/errors.py\", line 221, in default_errorhandler\n",
      "    raise error_class(\n",
      "snowflake.snowpark.exceptions.SnowparkSQLException: (1304): 01b53b75-0002-85c0-0001-8487017033c2: 100283 (P0000): Request failed for external function TEXT2SQL. Error: Couldn't connect to server\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/pygments/styles/__init__.py\", line 89, in get_style_by_name\n",
      "ModuleNotFoundError: No module named 'pygments.styles.default'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1396, in structured_traceback\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1287, in structured_traceback\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1140, in structured_traceback\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1030, in format_exception_as_a_whole\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1081, in get_records\n",
      "  File \"/Users/psheehan/miniconda3/envs/demosnowparkdemo/lib/python3.8/site-packages/pygments/styles/__init__.py\", line 91, in get_style_by_name\n",
      "pygments.util.ClassNotFound: Could not find style module 'default', though it should be builtin.\n"
     ]
    }
   ],
   "source": [
    "#Testing the function\n",
    "session.sql('''\n",
    "select text2sql('What is the distinct purpose of the calls in the last month?')::string;\n",
    "''').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark_3_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
