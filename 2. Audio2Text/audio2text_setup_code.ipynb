{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load requirements into conda "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b>In a new terminal, set your working directory to 2. Audio2Text and run the following commands</b>\n",
    "\n",
    "``` bash\n",
    "conda create --name demosnowparkdemo --override-channels -c https://repo.anaconda.com/pkgs/snowflake python=3.8 \n",
    "conda activate demosnowparkdemo\n",
    "conda install snowflake-snowpark-python pandas pyarrow streamlit\n",
    "pip install scikit-learn==1.1.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build docker image and push the image to image registry - BE SURE TO HAVE DOCKER RUNNING BEFORE PROCEEDING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b>Run the following commands from a terminal. Set your working directory to \"2. Audio2Text\". Ensure Docker is running on your laptop. Update the ORGNAME-ACCTNAME in the following commands with your Snowflake account info and provide correct username (you will be prompted for your password so have it handy).</b> \n",
    "\n",
    "``` bash\n",
    "-- Refer to \"2. Audio2Text\\Dockerfile\" for image details\n",
    "\n",
    "docker build --no-cache --platform linux/amd64 -t ORGNAME-ACCTNAME.registry.snowflakecomputing.com/llmdemo/public/images/whisper-audio2text:latest . \n",
    "\n",
    "docker push ORGNAME-ACCTNAME.registry.snowflakecomputing.com/llmdemo/public/images/whisper-audio2text:latest\n",
    "```\n",
    "> <b>*** Allow docker push to complete before moving on (takes several minutes, so now is a good time for a bio break) ***</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create internal stages to hold our images and files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection.json file should use the SPCS_PSE_ROLE \n",
    "\n",
    "connection_parameters = json.load(open('../connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stages for our files\n",
    "stages=['WHISPER_APP','AUDIO_FILES','SPECS','CSV_FILES']\n",
    "for stg in stages:\n",
    "    session.sql(f'''\n",
    "                CREATE OR REPLACE STAGE {stg} ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE') \n",
    "                DIRECTORY = (ENABLE = TRUE);\n",
    "                ''').collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. Create SPC Service\n",
    "Update the image url line in [whisper_spec.yml](./whisper_spec.yml) with your org/acct info prior to executing the following put command\n",
    "\n",
    "ex. image: <i>myorg-myaccount</i>.registry.snowflakecomputing.com/pr_llmdemo/public/image_repo/whisper-audio2text:latest\n",
    "\n",
    "PS: <b>Run following commands using the SPCS Role, not accountadmin! (this should already be set in your [connection.json](../connection.json) file) </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session.file.put(\"./whisper_spec.yml\", \"@specs\",auto_compress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the service\n",
    "session.sql('''\n",
    "CREATE SERVICE IF NOT EXISTS Whisper_Audio_text_SVC\n",
    "  IN COMPUTE POOL PR_GPU_S\n",
    "  FROM @specs\n",
    "  SPEC='whisper_spec.yml'\n",
    "  EXTERNAL_ACCESS_INTEGRATIONS = (ALLOW_ALL_EAI)\n",
    "  MIN_INSTANCES=1\n",
    "  MAX_INSTANCES=1;\n",
    "            ''').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The service must be in Ready State to proceed. Run the following command to confirm before proceeding to next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service activation will take several minutes, so just rerun this command until you see status READY (patience is a virtue)\n",
    "import ast\n",
    "res=session.sql(''' \n",
    "SELECT SYSTEM$GET_SERVICE_STATUS('Whisper_Audio_text_SVC',1)\n",
    "''').collect()[0][0]\n",
    "ast.literal_eval(res)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  Be sure the service is in the Ready State before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Check the log for the service for any errors.\n",
    "session.sql('''SELECT value AS log_line\n",
    "FROM TABLE(\n",
    " SPLIT_TO_TABLE(SYSTEM$GET_SERVICE_LOGS('Whisper_Audio_text_SVC', 0, 'audio-whisper-app'), '\\n')\n",
    "  )''').to_pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Creating the service function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Function to get duration of the audio files\n",
    "session.sql('''CREATE OR REPLACE FUNCTION DURATION(AUDIO_FILE TEXT)\n",
    "RETURNS VARIANT\n",
    "SERVICE=Whisper_Audio_text_SVC\n",
    "ENDPOINT=API\n",
    "AS '/audio-duration'\n",
    "            ''').collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transcribe the audio files\n",
    "session.sql('''CREATE OR REPLACE FUNCTION TRANSCRIBE(TASK TEXT, LANGUAGE TEXT, AUDIO_FILE TEXT, ENCODE BOOLEAN)\n",
    "RETURNS VARIANT\n",
    "SERVICE=Whisper_Audio_text_SVC\n",
    "ENDPOINT=API\n",
    "AS '/asr'\n",
    "            ''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect language of the audio file\n",
    "session.sql('''CREATE OR REPLACE FUNCTION DETECT_LANGUAGE(AUDIO_FILE TEXT, ENCODE BOOLEAN)\n",
    "RETURNS VARIANT\n",
    "SERVICE=Whisper_Audio_text_SVC\n",
    "ENDPOINT=API\n",
    "AS '/detect-language'\n",
    "            ''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Table to load the Audio file raw text along with duration and other attributes\n",
    "\n",
    "# Duration is in seconds\n",
    "\n",
    "session.sql('''\n",
    "    CREATE or REPLACE TABLE ALL_CLAIMS_RAW (\n",
    "\tDATETIME DATE,\n",
    "\tAUDIOFILE VARCHAR(16777216),\n",
    "\tCONVERSATION VARCHAR(16777216),\n",
    "\tPRESIGNED_URL_PATH VARCHAR(16777216),\n",
    "\tDURATION FLOAT NOT NULL\n",
    ")''').collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Uploading the audio files to Internal Stage\n",
    "\n",
    "_ = session.file.put(\"./audiofiles/*.*\", \"@AUDIO_FILES/2024-01-26/\", auto_compress=False,overwrite=True)\n",
    "\n",
    "session.sql(f'''ALTER STAGE AUDIO_FILES REFRESH''').collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql('ls @AUDIO_FILES/2024-01-26').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting records into the RAW Table\n",
    "# To have different values for the datetime, store your audio files in sub folders with yyy-mm-dd format . \n",
    "# E.g. 2024-01-10. \n",
    "session.sql('''\n",
    "INSERT INTO ALL_CLAIMS_RAW\n",
    "(\n",
    "DATETIME,\n",
    "AUDIOFILE,\n",
    "PRESIGNED_URL_PATH,\n",
    "CONVERSATION,\n",
    "DURATION\n",
    ")\n",
    "SELECT CAST(CASE WHEN split(RELATIVE_PATH,'/')[1]::string IS NULL THEN GETDATE() \n",
    "            ELSE split(RELATIVE_PATH,'/')[0]::string END AS DATE) as Datetime, \n",
    "        CASE WHEN split(RELATIVE_PATH,'/')[1]::string is null then split(RELATIVE_PATH,'/')[0]::string \n",
    "            ELSE split(RELATIVE_PATH,'/')[1]::string END as RELATIVE_PATH,\n",
    "       GET_PRESIGNED_URL('@AUDIO_FILES', RELATIVE_PATH) AS PRESIGNED_URL\n",
    "       -- ,DETECT_LANGUAGE(PRESIGNED_URL,TRUE) as DETECT_LANGUAGE\n",
    "       ,TRANSCRIBE('transcribe','',PRESIGNED_URL,True)['text']::string AS EXTRACTED_TEXT\n",
    "       ,DURATION(PRESIGNED_URL):call_duration_seconds::DOUBLE as CALL_DURATION_SECONDS\n",
    "FROM DIRECTORY('@AUDIO_FILES')\n",
    "            \n",
    "            ''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.table('ALL_CLAIMS_RAW').to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Loading Data into the ALL_CLAIMS_RAW Table from CSV\n",
    "\n",
    "Since we don't have lot of audio files from insurance industry, we will be loading sample data into the Raw table which has the raw conversation from the insurance industry. This data will be the source for this solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = session.file.put(\"./Sample_Audio_Text.csv\", \"@CSV_FILES\", auto_compress=False)\n",
    "\n",
    "sp_df=session.read.options({\"INFER_SCHEMA\":True,\"PARSE_HEADER\":True,\"FIELD_OPTIONALLY_ENCLOSED_BY\":'\"'}).csv('@CSV_FILES/Sample_Audio_Text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_df.write.mode(\"overwrite\").save_as_table(\"ALL_CLAIMS_RAW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.table('ALL_CLAIMS_RAW').to_pandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark_3_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
