{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "connection_parameters = json.load(open('../connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build docker image and push the image to image registry\n",
    "\n",
    "- Run the below code from terminal or execute the next cell by updating the connection details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Run below commands from a terminal. Update the ORGNAME-ACCTNAME and username -->\n",
    "``` bash\n",
    "cd ..\n",
    "cd text2sql\n",
    "```\n",
    "> be sure your directory has changed to text2sql (validate via pwd)\n",
    "``` bash\n",
    "docker build --no-cache --platform linux/amd64 -t ORGNAME-ACCTNAME.registry.snowflakecomputing.com/llmdemo/public/images/audiollm:latest . \n",
    "\n",
    "docker login ORGNAME-ACCTNAME.registry.snowflakecomputing.com -u <username>\n",
    "\n",
    "docker push ORGNAME-ACCTNAME.registry.snowflakecomputing.com/llmdemo/public/images/audiollm:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Creating Text2SQL SPC Service\n",
    "\n",
    "Update the image line in [llm-text2sql.yaml](./llm-text2sql.yaml) to provide your orgname-accountname values\n",
    "\n",
    "ex. image: <i>myorg-myaccount</i>.registry.snowflakecomputing.com/pr_llmdemo/public/image_repo/whisper-audio2text:latest\n",
    "\n",
    "PS: <b>Run following commands using the SPCS Role, not accountadmin! (this should already be set in your [connection.json](../connection.json) file) </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PutResult(source='llm-text2sql.yaml', target='llm-text2sql.yaml', source_size=648, target_size=648, source_compression='NONE', target_compression='NONE', status='UPLOADED', message='')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "session.file.put(\"./llm-text2sql.yaml\", \"@specs\",auto_compress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the required stage\n",
    "stages=['LLM_WORKSPACE']\n",
    "for stg in stages:\n",
    "    session.sql(f'''\n",
    "                CREATE STAGE IF NOT EXISTS {stg} ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE')\n",
    "                DIRECTORY = (ENABLE = TRUE);\n",
    "                ''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Service LLAMA_TEXT2SQL_SVC successfully created.')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the service. EXTERNAL_ACCESS_INTEGRATIONS(ALLOW_ALL_EAI) is created in audio2text/audio2text_setup_code.ipynb\n",
    "session.sql('''\n",
    "create service if not exists llama_text2sql_svc\n",
    "in compute pool PR_GPU_7\n",
    "from @specs\n",
    "SPECIFICATION_FILE='llm-text2sql.yaml'\n",
    "EXTERNAL_ACCESS_INTEGRATIONS = (ALLOW_ALL_EAI)\n",
    "            ''').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The service must be in Ready State to proceed. Run the following command to confirm before proceeding to next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'READY',\n",
       " 'message': 'Running',\n",
       " 'containerName': 'text2sql-container',\n",
       " 'instanceId': '0',\n",
       " 'serviceName': 'LLAMA_TEXT2SQL_SVC',\n",
       " 'image': 'sfsenorthamerica-demo-psheehan.registry.snowflakecomputing.com/llmdemo/public/images/audiollm:latest',\n",
       " 'restartCount': 0,\n",
       " 'startTime': '2024-06-21T18:09:42Z'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Check the status of service\n",
    "import ast\n",
    "res=session.sql(''' \n",
    "SELECT SYSTEM$GET_SERVICE_STATUS('llama_text2sql_svc',1)\n",
    "''').collect()[0][0]\n",
    "ast.literal_eval(res)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  Be sure the service is in the Ready State before procedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Accessing Jupyter Lab Endpoints\n",
    "Wait for the status of the service to be Running before moving to next step. \n",
    "\n",
    "Run the below query to get the api endpoint for the <b> jupyter lab </b>. Get the <b>ingress_url </b>(this endpoint will launch jupyter notebook running Snowpark Containers)  from the below query output.\n",
    "\n",
    "Ouput that you would get after running the below query.\n",
    "\n",
    "Row(name='llm-audio-ep', port=8888, protocol='TCP', ingress_enabled='true', ingress_url='test123-us-west-ccarrero-452.snowflakecomputing.app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(name='api', port=9000, port_range=None, protocol='HTTP', is_public='true', ingress_url='yjbzi-sfsenorthamerica-demo-psheehan.snowflakecomputing.app')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('''show endpoints in service llama_text2sql_svc;\n",
    "            ''').collect()[0]\n",
    "\n",
    "# Row(name='llm-audio-ep', port=8888, protocol='TCP', ingress_enabled='true', ingress_url='test123-us-west-ccarrero-452.snowflakecomputing.app')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Perform the following action on the Jupyter lab which is accessible from the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1. Open the terminal in the JupyterLab(which is running in Snowpark Containers) and run the below shell script  </b>\n",
    "\n",
    "- sh [./download_model.sh](https://github.com/Snowflake-Labs/sfguide-call-centre-analytics-with-snowflake-cortex-and-spcs/blob/main/text2sql/download_model.sh)\n",
    "\n",
    "This file will download the Numberstation model from hugging face and downloads to the stage which is mounted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2. Run the [FineTuneModel.ipynb](https://github.com/Snowflake-Labs/sfguide-call-centre-analytics-with-snowflake-cortex-and-spcs/blob/main/text2sql/FineTuneModel.ipynb)  </b>\n",
    "\n",
    "* Execute each cell by cell where we are fine tuning the model as well with our own dataset.\n",
    "\n",
    "* After executing the last cell you will be running a fast api service which will expose the Number station LLM as a api endpoint.\n",
    "\n",
    "><b> PS </b> : You need to execute step 1 and 2 only one time and from next time after you start the Snowpark service, run the below command from the terminal launched in the jupyter lab:\n",
    "\n",
    " * <b> sh [RunFastAPI.sh](https://github.com/Snowflake-Labs/sfguide-call-centre-analytics-with-snowflake-cortex-and-spcs/blob/main/text2sql/RunFastAPI.sh) </b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Execute the below commands to create the service function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql('''CREATE OR REPLACE FUNCTION text2sql(text TEXT)\n",
    "RETURNS VARIANT\n",
    "SERVICE=llama_text2sql_svc\n",
    "ENDPOINT=api\n",
    "AS '/text2sql\n",
    "            ''').collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the function\n",
    "session.sql('''\n",
    "select text2sql('What is the distinct purpose of the calls in the last month?')::string;\n",
    "''').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark_3_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
