{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "connection_parameters = json.load(open('../connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build docker image and push the image to image registry\n",
    "\n",
    "- Run the follolwing commands from terminal. <b>Set your working directory to 3. Text2SQL. </b>\n",
    "\n",
    "``` bash\n",
    "docker build --no-cache --platform linux/amd64 -t ORGNAME-ACCTNAME.registry.snowflakecomputing.com/llmdemo/public/images/audiollm:latest . \n",
    "\n",
    "docker push ORGNAME-ACCTNAME.registry.snowflakecomputing.com/llmdemo/public/images/audiollm:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Creating Text2SQL SPC Service\n",
    "\n",
    "Update the image line in [llm-text2sql.yaml](./llm-text2sql.yaml) to provide your orgname-accountname values\n",
    "\n",
    "ex. image: <i>myorg-myaccount</i>.registry.snowflakecomputing.com/pr_llmdemo/public/image_repo/whisper-audio2text:latest\n",
    "\n",
    "PS: <b>Run following commands using the SPCS Role, not accountadmin! (this should already be set in your [connection.json](../connection.json) file) </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PutResult(source='llm-text2sql.yaml', target='llm-text2sql.yaml', source_size=648, target_size=648, source_compression='NONE', target_compression='NONE', status='UPLOADED', message='')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "session.file.put(\"./llm-text2sql.yaml\", \"@specs\",auto_compress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the required stage\n",
    "stages=['LLM_WORKSPACE']\n",
    "for stg in stages:\n",
    "    session.sql(f'''\n",
    "                CREATE STAGE IF NOT EXISTS {stg} ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE')\n",
    "                DIRECTORY = (ENABLE = TRUE);\n",
    "                ''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Service LLAMA_TEXT2SQL_SVC successfully created.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the service. Depending on timing, the compute pool may auto-suspend. \n",
    "# If you see an error message ending in \"Compute Pool PR_GPU_7 is suspended.\", run the following command in Snowsight: \n",
    "# ALTER COMPUTE POOL PR_GPU_7 RESUME;\n",
    "session.sql('''\n",
    "create service if not exists llama_text2sql_svc\n",
    "in compute pool PR_GPU_7\n",
    "from @specs\n",
    "SPECIFICATION_FILE='llm-text2sql.yaml'\n",
    "EXTERNAL_ACCESS_INTEGRATIONS = (ALLOW_ALL_EAI)\n",
    "            ''').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The service must be in Ready State to proceed. Run the following command to confirm before proceeding to next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'READY',\n",
       " 'message': 'Running',\n",
       " 'containerName': 'text2sql-container',\n",
       " 'instanceId': '0',\n",
       " 'serviceName': 'LLAMA_TEXT2SQL_SVC',\n",
       " 'image': 'sfsenorthamerica-demo-psheehan.registry.snowflakecomputing.com/llmdemo/public/images/audiollm:latest',\n",
       " 'restartCount': 0,\n",
       " 'startTime': '2024-06-26T17:42:05Z'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Service activation will take several minutes, so just rerun this command until you see status READY (patience is a virtue)\n",
    "import ast\n",
    "res=session.sql(''' \n",
    "SELECT SYSTEM$GET_SERVICE_STATUS('llama_text2sql_svc',1)\n",
    "''').collect()[0][0]\n",
    "ast.literal_eval(res)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  Be sure the service is in the Ready State before procedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Accessing Jupyter Lab Endpoints\n",
    "Wait for the status of the service to be Running before moving to next step. \n",
    "\n",
    "Run the below query to get the api endpoint for the <b> jupyter lab </b>. Get the <b>ingress_url </b>(this endpoint will launch jupyter notebook running Snowpark Containers)  from the below query output.\n",
    "\n",
    "Output will be similar to this:  Row(name='llm-audio-ep', port=8888, port_range=None, protocol='HTTP', is_public='true', ingress_url='yjb2m-sfsenorthamerica-demo-psheehan.snowflakecomputing.app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(name='llm-audio-ep', port=8888, port_range=None, protocol='HTTP', is_public='true', ingress_url='yjb3i-sfsenorthamerica-demo-psheehan.snowflakecomputing.app')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('''show endpoints in service llama_text2sql_svc;\n",
    "            ''').collect()[1]\n",
    "\n",
    "# Row(name='llm-audio-ep', port=8888, port_range=None, protocol='HTTP', is_public='true', ingress_url='yjb2m-sfsenorthamerica-demo-psheehan.snowflakecomputing.app')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Perform the following action on the Jupyter lab which is accessible from the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 1. Open the terminal in the JupyterLab(which is running in Snowpark Containers) and run the following shell script. Wait until download is complete before proceeding to next step.  </b>\n",
    "\n",
    "- sh download_model.sh\n",
    "\n",
    "This file will download the Numberstation model from hugging face to a stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> 2. Run the FineTuneModel.ipynb</b>\n",
    "\n",
    "* Execute each cell by cell where we are fine tuning the model as well with our own dataset.\n",
    "\n",
    "* After executing the last cell you will be running a fast api service which will expose the Number station LLM as a api endpoint.\n",
    "\n",
    "><b> NOTE </b> : Steps 1 and 2 are one-time only; if you restart the Snowpark service, relaunch the jupyter lab from Step 4 above and then run the following terminal command:\n",
    "\n",
    "sh RunFastAPI.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Execute the below commands to create the service function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='Function TEXT2SQL successfully created.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql('''CREATE OR REPLACE FUNCTION text2sql(text TEXT)\n",
    "RETURNS VARIANT\n",
    "SERVICE=llama_text2sql_svc\n",
    "ENDPOINT=api\n",
    "AS '/text2sql' ''').collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(TEXT2SQL('WHAT IS THE DISTINCT PURPOSE OF THE CALLS IN THE LAST MONTH?')::STRING='SELECT DISTINCT PURPOSEOFCALL FROM STREAMLITAPPTABLE WHERE DATETIME >= CURRENT_TIMESTAMP() - 30')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing the function\n",
    "session.sql('''\n",
    "select text2sql('What is the distinct purpose of the calls in the last month?')::string;\n",
    "''').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark_3_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
